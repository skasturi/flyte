---
# Source: flyte/templates/pytorch-operator/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: pytorch-operator
---
# Source: flyte/charts/sparkoperator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flyte-sparkoperator
  labels:
    helm.sh/chart: sparkoperator-1.0.6
    app.kubernetes.io/name: sparkoperator
    app.kubernetes.io/instance: flyte
    app.kubernetes.io/version: "v1beta2-1.2.0-3.0.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: flyte/charts/sparkoperator/templates/spark-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flyte-spark
  namespace: flyte
  labels:
    helm.sh/chart: sparkoperator-1.0.6
    app.kubernetes.io/name: sparkoperator
    app.kubernetes.io/instance: flyte
    app.kubernetes.io/version: "v1beta2-1.2.0-3.0.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: flyte/templates/admin/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flyteadmin
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
  annotations: 
    eks.amazonaws.com/role-arn: arn:aws:iam::<ACCOUNT_NUMBER>:role/iam-role-flyte
---
# Source: flyte/templates/datacatalog/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: datacatalog
  namespace: flyte
  labels: 
    app.kubernetes.io/name: datacatalog
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
  annotations: 
    eks.amazonaws.com/role-arn: arn:aws:iam::<ACCOUNT_NUMBER>:role/iam-role-flyte
---
# Source: flyte/templates/propeller/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flytepropeller
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
  annotations: 
    eks.amazonaws.com/role-arn: arn:aws:iam::<ACCOUNT_NUMBER>:role/iam-role-flyte
---
# Source: flyte/templates/propeller/webhook.yaml
# Create a Service Account for webhook
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flyte-pod-webhook
  namespace: flyte
---
# Source: flyte/templates/pytorch-operator/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pytorch-operator
  namespace: pytorch-operator
  labels: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
---
# Source: flyte/templates/admin/secret-auth.yaml
apiVersion: v1
kind: Secret
metadata:
  name: flyte-admin-secrets
  namespace: flyte
type: Opaque
stringData:
---
# Source: flyte/templates/common/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-pass
stringData:
  pass.txt: '<DB_PASSWORD>'
type: Opaque
---
# Source: flyte/templates/propeller/secret-auth.yaml
apiVersion: v1
kind: Secret
metadata:
  name: flyte-propeller-auth
  namespace: flyte
type: Opaque
stringData:
  client_secret: foobar
---
# Source: flyte/templates/propeller/webhook.yaml
# Create an empty secret that the first propeller pod will populate
apiVersion: v1
kind: Secret
metadata:
  name: flyte-pod-webhook
  namespace: flyte
type: Opaque
---
# Source: flyte/templates/admin/cluster_resource_configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: clusterresource-template
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
data:
  aa_namespace.yaml: | 
    apiVersion: v1
    kind: Namespace
    metadata:
      name: {{ namespace }}
    spec:
      finalizers:
      - kubernetes
    
  aab_default_service_account.yaml: | 
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: default
      namespace: {{ namespace }}
      annotations:
        eks.amazonaws.com/role-arn: {{ defaultIamRole }}
    
  ab_project_resource_quota.yaml: | 
    apiVersion: v1
    kind: ResourceQuota
    metadata:
      name: project-quota
      namespace: {{ namespace }}
    spec:
      hard:
        limits.cpu: {{ projectQuotaCpu }}
        limits.memory: {{ projectQuotaMemory }}
    
  ad_spark_role.yaml: | 
    apiVersion: rbac.authorization.k8s.io/v1beta1
    kind: Role
    metadata:
      name: spark-role
      namespace: {{ namespace }}
    rules:
    - apiGroups:
      - ""
      resources:
      - pods
      verbs:
      - '*'
    - apiGroups:
      - ""
      resources:
      - services
      verbs:
      - '*'
    - apiGroups:
      - ""
      resources:
      - configmaps
      verbs:
      - '*'
    
  ae_spark_service_account.yaml: | 
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: spark
      namespace: {{ namespace }}
      annotations:
        eks.amazonaws.com/role-arn: {{ defaultIamRole }}
    
  af_spark_role_binding.yaml: | 
    apiVersion: rbac.authorization.k8s.io/v1beta1
    kind: RoleBinding
    metadata:
      name: spark-role-binding
      namespace: {{ namespace }}
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: Role
      name: spark-role
    subjects:
    - kind: ServiceAccount
      name: spark
      namespace: {{ namespace }}
    
  zz_copilot_config.yaml: | 
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: flyte-data-config
      namespace: {{ namespace }}
    data:
      config.yaml: | 
        storage:
          type: s3
          container: "<BUCKET_NAME>"
          connection:
            auth-type: iam
            region: <AWS_REGION>
          enable-multicontainer: true
---
# Source: flyte/templates/admin/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flyte-admin-config
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
data:
  db.yaml: | 
    database:
      dbname: flyteadmin
      host: '<RDS_HOST>'
      passwordPath: /etc/db/pass.txt
      port: 5432
      username: flyteadmin
  domain.yaml: | 
    domains:
    - id: development
      name: development
    - id: staging
      name: staging
    - id: production
      name: production
  logger.yaml: | 
    logger:
      level: 5
      show-source: true
  server.yaml: | 
    auth:
      appAuth:
        thirdPartyConfig:
          flyteClient:
            clientId: flytectl
            redirectUri: http://localhost:53593/callback
            scopes:
            - offline
            - all
      authorizedUris:
      - https://localhost:30081
      - http://flyteadmin:80
      - http://flyteadmin.flyte.svc.cluster.local:80
      userAuth:
        openId:
          baseUrl: https://accounts.google.com
          clientId: 657465813211-6eog7ek7li5k7i7fvgv2921075063hpe.apps.googleusercontent.com
          scopes:
          - profile
          - openid
    flyteadmin:
      eventVersion: 2
      metadataStoragePrefix:
      - metadata
      - admin
      metricsScope: 'flyte:'
      profilerPort: 10254
      roleNameKey: iam.amazonaws.com/role
      testing:
        host: http://flyteadmin
    server:
      grpcPort: 8089
      httpPort: 8088
      security:
        allowCors: true
        allowedHeaders:
        - Content-Type
        allowedOrigins:
        - '*'
        secure: false
        useAuth: false
  remoteData.yaml: | 
    remoteData:
      region: us-east-1
      scheme: local
      signedUrls:
        durationMinutes: 3
  storage.yaml: | 
    storage:
      type: s3
      container: "<BUCKET_NAME>"
      connection:
        auth-type: iam
        region: <AWS_REGION>
      limits:
        maxDownloadMBs: 10
  task_resource_defaults.yaml: | 
    task_resources:
      defaults:
        cpu: 1000m
        memory: 1000Mi
        storage: 1000Mi
      limits:
        cpu: 2
        gpu: 1
        memory: 1Gi
        storage: 2000Mi
  cluster_resources.yaml: | 
    cluster_resources:
      customData:
      - production:
        - projectQuotaCpu:
            value: "5"
        - projectQuotaMemory:
            value: 4000Mi
        - defaultIamRole:
            value: arn:aws:iam::<ACCOUNT_NUMBER>:role/flyte-user-role
      - staging:
        - projectQuotaCpu:
            value: "2"
        - projectQuotaMemory:
            value: 3000Mi
        - defaultIamRole:
            value: arn:aws:iam::<ACCOUNT_NUMBER>:role/flyte-user-role
      - development:
        - projectQuotaCpu:
            value: "4"
        - projectQuotaMemory:
            value: 3000Mi
        - defaultIamRole:
            value: arn:aws:iam::<ACCOUNT_NUMBER>:role/flyte-user-role
      refresh: 5m
      refreshInterval: 5m
      templatePath: /etc/flyte/clusterresource/templates
---
# Source: flyte/templates/console/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flyte-console-config
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteconsole
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
data: 
  BASE_URL: /console
  CONFIG_DIR: /etc/flyte/config
  DISABLE_AUTH: "1"
---
# Source: flyte/templates/datacatalog/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: datacatalog-config
  namespace: flyte
  labels: 
    app.kubernetes.io/name: datacatalog
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
data:
  db.yaml: | 
    database:
      dbname: flyteadmin
      host: '<RDS_HOST>'
      passwordPath: /etc/db/pass.txt
      port: 5432
      username: flyteadmin
  logger.yaml: | 
    logger:
      level: 5
      show-source: true
  server.yaml: | 
    application:
      grpcPort: 8089
      grpcServerReflection: true
      httpPort: 8080
    datacatalog:
      metrics-scope: datacatalog
      profiler-port: 10254
      storage-prefix: metadata/datacatalog
  storage.yaml: | 
    storage:
      type: s3
      container: "<BUCKET_NAME>"
      connection:
        auth-type: iam
        region: <AWS_REGION>
      limits:
        maxDownloadMBs: 10
---
# Source: flyte/templates/propeller/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flyte-propeller-config
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
data:
  admin.yaml: | 
    admin:
      clientId: flytepropeller
      clientSecretLocation: /etc/secrets/client_secret
      endpoint: flyteadmin:81
      insecure: true
    event:
      capacity: 1000
      rate: 500
      type: admin
  catalog.yaml: | 
    catalog-cache:
      endpoint: datacatalog:89
      insecure: true
      type: datacatalog
  copilot.yaml: | 
    plugins:
      k8s:
        co-pilot:
          image: cr.flyte.org/lyft/flyteplugins/flytecopilot:dc4bdbd61cac88a39a5ff43e40f026bdbc2c78a2
          name: flyte-copilot-
          start-timeout: 30s
  core.yaml: | 
    propeller:
      downstream-eval-duration: 30s
      enable-admin-launcher: true
      gc-interval: 12h
      kube-client-config:
        burst: 25
        qps: 100
        timeout: 30s
      leader-election:
        enabled: true
        lease-duration: 15s
        lock-config-map:
          name: propeller-leader
          namespace: flyte
        renew-deadline: 10s
        retry-period: 2s
      limit-namespace: all
      max-workflow-retries: 50
      metadata-prefix: metadata/propeller
      metrics-prefix: flyte
      prof-port: 10254
      queue:
        batch-size: -1
        batching-interval: 2s
        queue:
          base-delay: 5s
          capacity: 1000
          max-delay: 120s
          rate: 100
          type: maxof
        sub-queue:
          capacity: 1000
          rate: 100
          type: bucket
        type: batch
      rawoutput-prefix: s3://<BUCKET_NAME>/
      workers: 40
      workflow-reeval-duration: 30s
    webhook:
      certDir: /etc/webhook/certs
      serviceName: flyte-pod-webhook
  enabled_plugins.yaml: | 
    tasks:
      task-plugins:
        default-for-task-types:
          container: container
          container_array: k8s-array
          hive: athena
          pytorch: pytorch
          sidecar: sidecar
          spark: spark
        enabled-plugins:
        - container
        - sidecar
        - spark
        - k8s-array
        - pytorch
        - athena
  k8s.yaml: | 
    plugins:
      k8s:
        default-cpus: 100m
        default-env-vars: []
        default-memory: 100Mi
  logger.yaml: | 
    logger:
      level: 5
      show-source: true
  resource_manager.yaml: | 
    propeller:
      resourcemanager:
        redis:
          hostKey: mypassword
          hostPath: redis-resource-manager:6379
        resourceMaxQuota: 10000
        type: redis
  spark.yaml: | 
    plugins:
      spark:
        spark-config-default:
        - spark.hadoop.fs.s3a.aws.credentials.provider: com.amazonaws.auth.DefaultAWSCredentialsProviderChain
        - spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version: "2"
        - spark.kubernetes.allocation.batch.size: "50"
        - spark.hadoop.fs.s3a.acl.default: BucketOwnerFullControl
        - spark.hadoop.fs.s3n.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
        - spark.hadoop.fs.AbstractFileSystem.s3n.impl: org.apache.hadoop.fs.s3a.S3A
        - spark.hadoop.fs.s3.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
        - spark.hadoop.fs.AbstractFileSystem.s3.impl: org.apache.hadoop.fs.s3a.S3A
        - spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
        - spark.hadoop.fs.AbstractFileSystem.s3a.impl: org.apache.hadoop.fs.s3a.S3A
        - spark.hadoop.fs.s3a.multipart.threshold: "536870912"
        - spark.blacklist.enabled: "true"
        - spark.blacklist.timeout: 5m
        - spark.task.maxfailures: "8"
  storage.yaml: | 
    storage:
      type: s3
      container: "<BUCKET_NAME>"
      connection:
        auth-type: iam
        region: <AWS_REGION>
      limits:
        maxDownloadMBs: 10
  cache.yaml: |
    cache:
      max_size_mbs: 1024
      target_gc_percent: 70
  task_logs.yaml: | 
    plugins:
      logs:
        cloudwatch-enabled: true
        cloudwatch-log-group: '<LOG_GROUP_NAME>'
        cloudwatch-region: '<AWS_REGION>'
        kubernetes-enabled: false
---
# Source: flyte/templates/propeller/crds/flyteworkflow.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: flyteworkflows.flyte.lyft.com
spec:
  group: flyte.lyft.com
  names:
    kind: FlyteWorkflow
    plural: flyteworkflows
    shortNames:
    - fly
    singular: flyteworkflow
  scope: Namespaced
  version: v1alpha1
---
# Source: flyte/templates/pytorch-operator/crds/pytorchjobs.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: pytorchjobs.kubeflow.org
spec:
  additionalPrinterColumns:
  - JSONPath: .status.conditions[-1:].type
    name: State
    type: string
  - JSONPath: .metadata.creationTimestamp
    name: Age
    type: date
  group: kubeflow.org
  names:
    kind: PyTorchJob
    plural: pytorchjobs
    singular: pytorchjob
  scope: Namespaced
  subresources:
    status: {}
  validation:
    openAPIV3Schema:
      properties:
        spec:
          properties:
            pytorchReplicaSpecs:
              properties:
                Master:
                  properties:
                    replicas:
                      maximum: 1
                      minimum: 1
                      type: integer
                Worker:
                  properties:
                    replicas:
                      minimum: 1
                      type: integer
  versions:
  - name: v1
    served: true
    storage: true
---
# Source: flyte/charts/sparkoperator/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: flyte-sparkoperator
  labels:
    helm.sh/chart: sparkoperator-1.0.6
    app.kubernetes.io/name: sparkoperator
    app.kubernetes.io/instance: flyte
    app.kubernetes.io/version: "v1beta2-1.2.0-3.0.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - "*"
- apiGroups:
  - ""
  resources:
  - services
  - configmaps
  - secrets
  verbs:
  - create
  - get
  - delete
  - update
- apiGroups:
  - extensions
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - create
  - get
  - delete
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - update
  - patch
- apiGroups:
  - ""
  resources:
  - resourcequotas
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - create
  - get
  - update
  - delete
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  - validatingwebhookconfigurations
  verbs:
  - create
  - get
  - update
  - delete
- apiGroups:
  - sparkoperator.k8s.io
  resources:
  - sparkapplications
  - sparkapplications/status
  - scheduledsparkapplications
  - scheduledsparkapplications/status
  verbs:
  - "*"
---
# Source: flyte/templates/admin/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: flyteadmin
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  - flyte.lyft.com
  - rbac.authorization.k8s.io
  resources:
  - configmaps
  - flyteworkflows
  - namespaces
  - pods
  - resourcequotas
  - roles
  - rolebindings
  - secrets
  - services
  - serviceaccounts
  - spark-role
  verbs:
  - '*'
---
# Source: flyte/templates/propeller/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: flytepropeller
  labels: 
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
rules:
# Allow RO access to PODS
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
# Allow Event recording access
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - update
  - delete
  - patch
# Allow Access All plugin objects
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - delete
  - patch
# Allow Access to CRD
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - update
# Allow Access to all resources under flyte.lyft.com
- apiGroups:
  - flyte.lyft.com
  resources:
  - flyteworkflows
  - flyteworkflows/finalizers
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - delete
  - patch
  - post
  - deletecollection
---
# Source: flyte/templates/propeller/webhook.yaml
# Create a ClusterRole for the webhook
# https://kubernetes.io/docs/admin/authorization/rbac/
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: flyte-pod-webhook
  namespace: flyte
rules:
  - apiGroups:
      - "*"
    resources:
      - mutatingwebhookconfigurations
      - secrets
      - pods
    verbs:
      - get
      - create
      - update
      - patch
---
# Source: flyte/templates/pytorch-operator/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pytorch-operator-admin
  labels: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
rules: []
aggregationRule:
  clusterRoleSelectors:
  - matchLabels:
      rbac.authorization.kubeflow.org/aggregate-to-kubeflow-pytorchjobs-admin: "true"
---
# Source: flyte/templates/pytorch-operator/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pytorch-operator-edit
  labels: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - kubeflow.org
  resources:
  - pytorchjobs
  - pytorchjobs/status
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - deletecollection
  - patch
  - update
---
# Source: flyte/templates/pytorch-operator/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pytorch-operator-view
  labels: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - kubeflow.org
  resources:
  - pytorchjobs
  - pytorchjobs/status
  verbs:
  - get
  - list
  - watch
---
# Source: flyte/templates/pytorch-operator/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pytorch-operator
  labels: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - kubeflow.org
  resources:
  - pytorchjobs
  - pytorchjobs/status
  verbs:
  - '*'
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - pods
  - services
  - endpoints
  - events
  verbs:
  - '*'
---
# Source: flyte/charts/sparkoperator/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: flyte-sparkoperator
  labels:
    helm.sh/chart: sparkoperator-1.0.6
    app.kubernetes.io/name: sparkoperator
    app.kubernetes.io/instance: flyte
    app.kubernetes.io/version: "v1beta2-1.2.0-3.0.0"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: flyte-sparkoperator
    namespace: flyte
roleRef:
  kind: ClusterRole
  name: flyte-sparkoperator
  apiGroup: rbac.authorization.k8s.io
---
# Source: flyte/templates/admin/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: flyteadmin-binding
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flyteadmin
subjects:
- kind: ServiceAccount
  name: flyteadmin
  namespace: flyte
---
# Source: flyte/templates/propeller/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: flytepropeller
  labels: 
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flytepropeller
subjects:
- kind: ServiceAccount
  name: flytepropeller
  namespace: flyte
---
# Source: flyte/templates/propeller/webhook.yaml
# Create a binding from Role -> ServiceAccount
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: flyte-pod-webhook
  namespace: flyte
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flyte-pod-webhook
subjects:
  - kind: ServiceAccount
    name: flyte-pod-webhook
    namespace: flyte
---
# Source: flyte/templates/pytorch-operator/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: pytorch-operator
  labels: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pytorch-operator
subjects:
- kind: ServiceAccount
  name: pytorch-operator
  namespace: pytorch-operator
---
# Source: flyte/charts/sparkoperator/templates/spark-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: spark-role
  namespace: flyte
  labels:
    helm.sh/chart: sparkoperator-1.0.6
    app.kubernetes.io/name: sparkoperator
    app.kubernetes.io/instance: flyte
    app.kubernetes.io/version: "v1beta2-1.2.0-3.0.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - "*"
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - "*"
---
# Source: flyte/charts/sparkoperator/templates/spark-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: spark
  namespace: flyte
  labels:
    helm.sh/chart: sparkoperator-1.0.6
    app.kubernetes.io/name: sparkoperator
    app.kubernetes.io/instance: flyte
    app.kubernetes.io/version: "v1beta2-1.2.0-3.0.0"
    app.kubernetes.io/managed-by: Helm
subjects:
- kind: ServiceAccount
  name: flyte-spark
  namespace: flyte
roleRef:
  kind: Role
  name: spark-role
  apiGroup: rbac.authorization.k8s.io
---
# Source: flyte/templates/admin/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: flyteadmin
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
  annotations: 
    external-dns.alpha.kubernetes.io/hostname: flyte.example.com
    projectcontour.io/upstream-protocol.h2c: grpc
    service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "600"
spec:
  type: LoadBalancer
  loadBalancerSourceRanges:
    [0.0.0.0/0]
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8088
    - name: grpc
      port: 81
      protocol: TCP
      targetPort: 8089
    - name: redoc
      protocol: TCP
      port: 87
      targetPort: 8087
    - name: http-metrics
      protocol: TCP
      port: 10254
  selector: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
---
# Source: flyte/templates/console/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: flyteconsole
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteconsole
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
  annotations: 
    external-dns.alpha.kubernetes.io/hostname: flyte.example.com
    service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "600"
spec:
  type: LoadBalancer
  ports:
  - port: 80
    protocol: TCP
    targetPort: 8080
  selector: 
    app.kubernetes.io/name: flyteconsole
    app.kubernetes.io/instance: flyte
---
# Source: flyte/templates/datacatalog/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: datacatalog
  namespace: flyte
  labels: 
    app.kubernetes.io/name: datacatalog
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
  annotations: 
    projectcontour.io/upstream-protocol.h2c: grpc
    service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "600"
spec:
  type: LoadBalancer
  ports:
  - name: grpc-2
    port: 8089
    protocol: TCP
    targetPort: 8089
  - name: http
    port: 88
    protocol: TCP
    targetPort: 8088
  - name: grpc
    port: 89
    protocol: TCP
    targetPort: 8089
  selector: 
    app.kubernetes.io/name: datacatalog
    app.kubernetes.io/instance: flyte
---
# Source: flyte/templates/propeller/webhook.yaml
# Service
apiVersion: v1
kind: Service
metadata:
  name: flyte-pod-webhook
  namespace: flyte
  annotations: 
    projectcontour.io/upstream-protocol.h2c: grpc
spec:
  selector:
    app: flyte-pod-webhook
  ports:
    - name: https
      protocol: TCP
      port: 443
      targetPort: 9443
---
# Source: flyte/templates/pytorch-operator/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: pytorch-operator
  namespace: pytorch-operator
  labels: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
  - name: monitoring-port
    port: 8443
    targetPort: 8443
  selector: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
---
# Source: flyte/templates/redis/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: redis-resource-manager
  namespace: flyte
  labels: 
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
  - name: redis
    port: 6379
    protocol: TCP
    targetPort: redis
  selector: 
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: flyte
---
# Source: flyte/charts/sparkoperator/templates/deployment.yaml
# If the admission webhook is enabled, then a post-install step is required
# to generate and install the secret in the operator namespace.

# In the post-install hook, the token corresponding to the operator service account
# is used to authenticate with the Kubernetes API server to install the secret bundle.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: flyte-sparkoperator
  labels:
    helm.sh/chart: sparkoperator-1.0.6
    app.kubernetes.io/name: sparkoperator
    app.kubernetes.io/instance: flyte
    app.kubernetes.io/version: "v1beta2-1.2.0-3.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: sparkoperator
      app.kubernetes.io/instance: flyte
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "10254"
        prometheus.io/path: /metrics
      labels:
        app.kubernetes.io/name: sparkoperator
        app.kubernetes.io/instance: flyte
    spec:
      serviceAccountName: flyte-sparkoperator
      securityContext:
        {}
      containers:
      - name: sparkoperator
        image: gcr.io/spark-operator/spark-operator:v1beta2-1.2.0-3.0.0
        imagePullPolicy: IfNotPresent
        securityContext:
          {}
        ports:
          - name: "metrics"
            containerPort: 10254
        
        args:
        - -v=2
        - -logtostderr
        - -namespace=
        - -ingress-url-format=
        - -controller-threads=10
        - -resync-interval=30
        - -enable-batch-scheduler=false
        - -enable-metrics=true
        - -metrics-labels=app_type
        - -metrics-port=10254
        - -metrics-endpoint=/metrics
        - -metrics-prefix=
        - -enable-resource-quota-enforcement=false
        resources:
          limits:
            cpu: 1000m
            memory: 1000Mi
          requests:
            cpu: 50m
            memory: 250Mi
---
# Source: flyte/templates/admin/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flyteadmin
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels: 
      app.kubernetes.io/name: flyteadmin
      app.kubernetes.io/instance: flyte
  template:
    metadata:
      annotations:
        configChecksum: "faf2bd6b71f061de4716e29b46b929f85becc0030b93428c9f452b22dc19e04"
      labels: 
        app.kubernetes.io/name: flyteadmin
        app.kubernetes.io/instance: flyte
        helm.sh/chart: flyte-v0.1.10
        app.kubernetes.io/managed-by: Helm
    spec:
      initContainers:
        - command:
          - flyteadmin
          - --config
          - /etc/flyte/config/*.yaml
          - migrate
          - run
          image: "cr.flyte.org/flyteorg/flyteadmin:v0.6.43"
          imagePullPolicy: "IfNotPresent"
          name: run-migrations
          volumeMounts:
          - mountPath: /etc/db
            name: db-pass
          - mountPath: /etc/flyte/config
            name: config-volume
        - command:
          - flyteadmin
          - --config
          - /etc/flyte/config/*.yaml
          - migrate
          - seed-projects
          - flytesnacks
          - flytetester
          - flyteexamples
          image: "cr.flyte.org/flyteorg/flyteadmin:v0.6.43"
          imagePullPolicy: "IfNotPresent"
          name: seed-projects
          volumeMounts:
          - mountPath: /etc/db
            name: db-pass
          - mountPath: /etc/flyte/config
            name: config-volume
        - command:
          - flyteadmin
          - --config
          - /etc/flyte/config/*.yaml
          - clusterresource
          - sync
          image: "cr.flyte.org/flyteorg/flyteadmin:v0.6.43"
          imagePullPolicy: "IfNotPresent"
          name: sync-cluster-resources
          volumeMounts:
          - mountPath: /etc/db
            name: db-pass
          - mountPath: /etc/flyte/clusterresource/templates
            name: resource-templates
          - mountPath: /etc/flyte/config
            name: config-volume
        - name: generate-secrets
          image: "cr.flyte.org/flyteorg/flyteadmin:v0.6.43"
          imagePullPolicy: "IfNotPresent"
          command: ["/bin/sh", "-c"]
          args:
            [
                "flyteadmin --config=/etc/flyte/config/*.yaml secrets init --localPath /etc/secrets/auth && flyteadmin --config=/etc/flyte/config/*.yaml secrets create --name flyte-admin-secrets --fromPath /etc/secrets/auth",
            ]
          volumeMounts:
            - name: config-volume
              mountPath: /etc/flyte/config
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
      containers:
      - command:
        - flyteadmin
        - --config
        - /etc/flyte/config/*.yaml
        - serve
        image: "cr.flyte.org/flyteorg/flyteadmin:v0.6.43"
        imagePullPolicy: "IfNotPresent"
        name: flyteadmin
        ports:
        - containerPort: 8088
        - containerPort: 8089
        resources: 
          limits:
            cpu: 250m
            ephemeral-storage: 200Mi
            memory: 500Mi
          requests:
            cpu: 50m
            ephemeral-storage: 200Mi
            memory: 200Mi
        volumeMounts:
        - mountPath: /etc/db
          name: db-pass
        - mountPath: /srv/flyte
          name: shared-data
        - mountPath: /etc/flyte/config
          name: config-volume
        - name: auth
          mountPath: /etc/secrets/
      serviceAccountName: flyteadmin
      volumes:
        - name: db-pass
          secret:
            secretName: db-pass
        - emptyDir: {}
          name: shared-data
        - configMap:
            name: flyte-admin-config
          name: config-volume
        - configMap:
            name: clusterresource-template
          name: resource-templates
        - name: auth
          secret:
            secretName: flyte-admin-secrets
      affinity: 
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: flyteadmin
            topologyKey: kubernetes.io/hostname
---
# Source: flyte/templates/console/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flyteconsole
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteconsole
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels: 
      app.kubernetes.io/name: flyteconsole
      app.kubernetes.io/instance: flyte
  template:
    metadata:
      annotations:
        configChecksum: "8ef03d2ed4468082a4585c0454139c5df15794f3340e17c7ea338cd6e781b91"
      labels: 
        app.kubernetes.io/name: flyteconsole
        app.kubernetes.io/instance: flyte
        helm.sh/chart: flyte-v0.1.10
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
      - image: "cr.flyte.org/flyteorg/flyteconsole:v0.29.0"
        imagePullPolicy: "IfNotPresent"
        name: flyteconsole
        envFrom:
        - configMapRef:
            name: flyte-console-config
        ports:
        - containerPort: 8080
        resources: 
          limits:
            cpu: 250m
            memory: 250Mi
          requests:
            cpu: 10m
            memory: 50Mi
        volumeMounts:
        - mountPath: /srv/flyte
          name: shared-data
      volumes:
      - emptyDir: {}
        name: shared-data
      affinity: 
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: flyteconsole
            topologyKey: kubernetes.io/hostname
---
# Source: flyte/templates/datacatalog/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: datacatalog
  namespace: flyte
  labels: 
    app.kubernetes.io/name: datacatalog
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels: 
      app.kubernetes.io/name: datacatalog
      app.kubernetes.io/instance: flyte
  template:
    metadata:
      annotations:
        configChecksum: "0cf9d3a246a3eb65c44535f3ae9c441761bb4599ec44c50d433774959354336"
      labels: 
        app.kubernetes.io/name: datacatalog
        app.kubernetes.io/instance: flyte
        helm.sh/chart: flyte-v0.1.10
        app.kubernetes.io/managed-by: Helm
    spec:
      initContainers:
        - command:
            - datacatalog
            - --config
            - /etc/datacatalog/config/*.yaml
            - migrate
            - run
          image: "cr.flyte.org/flyteorg/datacatalog:v0.3.9"
          imagePullPolicy: "IfNotPresent"
          name: run-migrations
          volumeMounts:
            - mountPath: /etc/db
              name: db-pass
            - mountPath: /etc/datacatalog/config
              name: config-volume
      containers:
        - command:
            - datacatalog
            - --config
            - /etc/datacatalog/config/*.yaml
            - serve
          image: "cr.flyte.org/flyteorg/datacatalog:v0.3.9"
          imagePullPolicy: "IfNotPresent"
          name: datacatalog
          ports:
            - containerPort: 8088
            - containerPort: 8089
          resources: 
            limits:
              cpu: 500m
              ephemeral-storage: 200Mi
              memory: 500Mi
            requests:
              cpu: 50m
              ephemeral-storage: 200Mi
              memory: 200Mi
          volumeMounts:
            - mountPath: /etc/db
              name: db-pass
            - mountPath: /etc/datacatalog/config
              name: config-volume
      serviceAccountName: datacatalog
      volumes:
        - name: db-pass
          secret:
            secretName: db-pass
        - emptyDir: {}
          name: shared-data
        - configMap:
            name: datacatalog-config
          name: config-volume
      affinity: 
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: datacatalog
            topologyKey: kubernetes.io/hostname
---
# Source: flyte/templates/propeller/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flytepropeller
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels: 
      app.kubernetes.io/name: flytepropeller
      app.kubernetes.io/instance: flyte
  template:
    metadata:
      annotations:
        configChecksum: "1a4678d9e43881ab183a3fce7ee25de8c10b0d5f1cd91f108ff8dddc3cff99f"
      labels: 
        app.kubernetes.io/name: flytepropeller
        app.kubernetes.io/instance: flyte
        helm.sh/chart: flyte-v0.1.10
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
      - command:
        - flytepropeller
        - --config
        - /etc/flyte/config/*.yaml
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        image: "cr.flyte.org/flyteorg/flytepropeller:v0.14.13"
        imagePullPolicy: "IfNotPresent"
        name: flytepropeller
        ports:
        - containerPort: 10254
        resources: 
          limits:
            cpu: 1
            ephemeral-storage: 1Gi
            memory: 2Gi
          requests:
            cpu: 1
            ephemeral-storage: 1Gi
            memory: 2Gi
        volumeMounts:
          - name: config-volume
            mountPath: /etc/flyte/config
          - name: auth
            mountPath: /etc/secrets/
      serviceAccountName: flytepropeller
      volumes:
      - configMap:
          name: flyte-propeller-config
        name: config-volume
      - name: auth
        secret:
          secretName: flyte-propeller-auth
      affinity: 
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: flytepropeller
            topologyKey: kubernetes.io/hostname
---
# Source: flyte/templates/propeller/webhook.yaml
# Create the actual deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flyte-pod-webhook
  namespace: flyte
  labels:
    app: flyte-pod-webhook
spec:
  selector:
    matchLabels:
      app: flyte-pod-webhook
  template:
    metadata:
      labels:
        app: flyte-pod-webhook
        app.kubernetes.io/name: flyte-pod-webhook
        app.kubernetes.io/version: v0.14.13
      annotations:
        configChecksum: "1a4678d9e43881ab183a3fce7ee25de8c10b0d5f1cd91f108ff8dddc3cff99f"
    spec:
      serviceAccountName: flyte-pod-webhook
      initContainers:
      - name: generate-secrets
        image: "cr.flyte.org/flyteorg/flytepropeller:v0.14.13"
        imagePullPolicy: "IfNotPresent"
        command:
          - flytepropeller
        args:
          - webhook
          - init-certs
          - --config
          - /etc/flyte/config/*.yaml
        env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        volumeMounts:
          - name: config-volume
            mountPath: /etc/flyte/config
      containers:
        - name: webhook
          image: "cr.flyte.org/flyteorg/flytepropeller:v0.14.13"
          imagePullPolicy: "IfNotPresent"
          command:
            - flytepropeller
          args:
            - webhook
            - --config
            - /etc/flyte/config/*.yaml
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - name: config-volume
              mountPath: /etc/flyte/config
              readOnly: true
            - name: webhook-certs
              mountPath: /etc/webhook/certs
              readOnly: true
      volumes:
        - name: config-volume
          configMap:
            name: flyte-propeller-config
        - name: webhook-certs
          secret:
            secretName: flyte-pod-webhook
---
# Source: flyte/templates/pytorch-operator/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pytorch-operator
  namespace: pytorch-operator
  labels: 
    app.kubernetes.io/name: pytorch-operator
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/name: pytorch-operator
      app.kubernetes.io/instance: flyte
  template:
    metadata:
      labels: 
        app.kubernetes.io/name: pytorch-operator
        app.kubernetes.io/instance: flyte
        helm.sh/chart: flyte-v0.1.10
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
      - image: "gcr.io/kubeflow-images-public/pytorch-operator:v1.0.0-g047cf0f"
        imagePullPolicy: "IfNotPresent"
        name: pytorch-operator
        command:
        - /pytorch-operator.v1
        - --alsologtostderr
        - -v=1
        - --monitoring-port=8443
        env:
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        resources: 
          limits:
            cpu: 1000m
            memory: 1000Mi
          requests:
            cpu: 50m
            memory: 250Mi
      serviceAccountName: pytorch-operator
---
# Source: flyte/templates/redis/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
  namespace: flyte
  labels: 
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: flyte
  serviceName: redis-resource-manager
  template:
    metadata:
      labels: 
        app.kubernetes.io/name: redis
        app.kubernetes.io/instance: flyte
        helm.sh/chart: flyte-v0.1.10
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
      - image: "ecr.flyte.org/bitnami/redis:6.2.5-debian-10-r59"
        imagePullPolicy: "IfNotPresent"
        name: redis
        env:
        - name: REDIS_PASSWORD
          value: mypassword
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          failureThreshold: 3
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        ports:
        - containerPort: 6379
          name: redis
          protocol: TCP
        resources: 
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 250Mi
        volumeMounts:
        - mountPath: /bitnami
          name: redis-data
     
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      volumes:
      - emptyDir: {}
        name: redis-data
---
# Source: flyte/templates/admin/cronjob.yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: syncresources
  namespace: flyte
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: flyte
    helm.sh/chart: flyte-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  schedule: '*/1 * * * *'
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - command:
            - flyteadmin
            - --config
            - /etc/flyte/config/*.yaml
            - clusterresource
            - sync
            image: "cr.flyte.org/flyteorg/flyteadmin:v0.6.43"
            imagePullPolicy: "IfNotPresent"
            name: sync-cluster-resources
            volumeMounts:
            - mountPath: /etc/db
              name: db-pass
            - mountPath: /etc/flyte/clusterresource/templates
              name: resource-templates
            - mountPath: /etc/flyte/config
              name: config-volume
          restartPolicy: OnFailure
          serviceAccountName: flyteadmin
          volumes:
          - name: db-pass
            secret:
              secretName: db-pass
          - configMap:
              name: clusterresource-template
            name: resource-templates
          - configMap:
              name: flyte-admin-config
            name: config-volume
---
# Source: flyte/templates/common/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: flyte
  namespace: flyte
  annotations: 
    alb.ingress.kubernetes.io/actions.ssl-redirect: '{"Type": "redirect", "RedirectConfig":
      { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}}'
    alb.ingress.kubernetes.io/certificate-arn: '<CERTIFICATE_ARN>'
    alb.ingress.kubernetes.io/group.name: flyte
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/tags: service_instance=production
    kubernetes.io/ingress.class: alb
    nginx.ingress.kubernetes.io/app-root: /console
spec:
  rules:
    - http:
        paths:
          - path: /*
            pathType: ImplementationSpecific
            backend:
              serviceName: ssl-redirect
              servicePort: use-annotation
          # This is useful only for frontend development
          # Port 87 in FlyteAdmin maps to the redoc container.
          - path: /openapi
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 87
          # NOTE: If you change this, you must update the BASE_URL value in flyteconsole.yaml
          - path: /console
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteconsole
              servicePort: 80
          - path: /console/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteconsole
              servicePort: 80
          - path: /api
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /api/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /healthcheck
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /v1/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          # Port 87 in FlyteAdmin maps to the redoc container.
          - path: /openapi/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 87
          - path: /.well-known
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /.well-known/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /login
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /login/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /logout
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /logout/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /callback
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /callback/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /me
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /config
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /config/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /oauth2
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
          - path: /oauth2/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 80
# Certain ingress controllers like nginx cannot serve HTTP 1 and GRPC with a single ingress because GRPC can only
# enabled on the ingress object, not on backend services (GRPC annotation is set on the ingress, not on the services).
---
# Source: flyte/templates/common/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: flyte-grpc
  namespace: flyte
  annotations:
    alb.ingress.kubernetes.io/actions.ssl-redirect: '{"Type": "redirect", "RedirectConfig":
      { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}}'
    alb.ingress.kubernetes.io/certificate-arn: '<CERTIFICATE_ARN>'
    alb.ingress.kubernetes.io/group.name: flyte
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/tags: service_instance=production
    kubernetes.io/ingress.class: alb
    nginx.ingress.kubernetes.io/app-root: /console
    alb.ingress.kubernetes.io/backend-protocol-version: HTTP2
    nginx.ingress.kubernetes.io/backend-protocol: GRPC
spec:
  rules:
    - http:
        paths:
          #
          # - backend:
          #     serviceName: ssl-redirect
          #     servicePort: use-annotation
          #   path: /*
          #   pathType: ImplementationSpecific
          #
          # NOTE: Port 81 in flyteadmin is the GRPC server port for FlyteAdmin.
          - path: /flyteidl.service.AdminService
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 81
          - path: /flyteidl.service.AdminService/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 81
          - path: /flyteidl.service.AuthMetadataService
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 81
          - path: /flyteidl.service.AuthMetadataService/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 81
          - path: /flyteidl.service.IdentityService
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 81
          - path: /flyteidl.service.IdentityService/*
            pathType: ImplementationSpecific
            backend:
              serviceName: flyteadmin
              servicePort: 81
